{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1HhkPKg_tYX"
      },
      "source": [
        "Assignmnet 1: Image Classification with Neural Networks\n",
        "=====================\n",
        "\n",
        "Data in Deep Learning\n",
        "----------------\n",
        "\n",
        "Generally, when you have to deal with image, text, audio or video data,\n",
        "you can use standard python packages that load data into a numpy array.\n",
        "Then you can convert this array into a ``torch.*Tensor``.\n",
        "\n",
        "-  For images, packages such as Pillow, OpenCV are useful\n",
        "-  For audio, packages such as scipy and librosa\n",
        "-  For text, either raw Python or Cython based loading, or NLTK and\n",
        "   SpaCy are useful\n",
        "\n",
        "Specifically for vision, we have created a package called\n",
        "``torchvision``, that has data loaders for common datasets such as\n",
        "ImageNet, CIFAR10, MNIST, etc. and data transformers for images, viz.,\n",
        "``torchvision.datasets`` and ``torch.utils.data.DataLoader``.\n",
        "\n",
        "This provides a huge convenience and avoids writing boilerplate code.\n",
        "\n",
        "For this assignment, we will use the CIFAR10 dataset.\n",
        "\n",
        "It has the classes:\n",
        "\n",
        "‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,\n",
        "‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’.\n",
        "\n",
        "The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
        "\n",
        "\n",
        "Training an image classifier\n",
        "----------------------------\n",
        "\n",
        "We will do the following steps in order:\n",
        "\n",
        "1. Load and normalize the CIFAR10 training and test datasets using\n",
        "   ``torchvision``\n",
        "2. Define a Convolutional Neural Network\n",
        "3. Define a loss function\n",
        "4. Train the network on the training data\n",
        "5. Test the network on the test data\n",
        "\n",
        "1. Load and normalize CIFAR10\n",
        "\n",
        "\n",
        "Using ``torchvision``, it’s extremely easy to load CIFAR10.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rOUZ6PvP_tYd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCINS4Xl_tYe"
      },
      "source": [
        "## Define the dataset and dataloader\n",
        "\n",
        "The output of torchvision datasets are PILImage images of range [0, 1].\n",
        "We transform them to Tensors of normalized range [-1, 1].\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0xCks16_tYe",
        "outputId": "6b397548-56ad-404b-c300-8d1f8548df70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:04<00:00, 38459491.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "def get_vis_loader():\n",
        "    transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                            download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                              shuffle=True, num_workers=2)\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                           download=True, transform=transform)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                             shuffle=False, num_workers=2)\n",
        "    return trainloader, testloader\n",
        "\n",
        "def get_train_loader(batch_size, transform):\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                            download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                              shuffle=True, num_workers=2)\n",
        "    return trainloader\n",
        "\n",
        "def get_test_loader(batch_size, transform):\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                           download=True, transform=transform)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                             shuffle=False, num_workers=2)\n",
        "    return testloader\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "vistrainloader, vistestloader = get_vis_loader()\n",
        "trainloader = get_train_loader(batch_size, transform)\n",
        "testloader = get_test_loader(batch_size, transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJWLkwxT_tYf"
      },
      "source": [
        "## Visualization\n",
        "\n",
        "Let us show some of the training images, for fun.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "nSy_x5M9_tYf",
        "outputId": "78f394a8-27b2-462a-ba5f-60de6315b859"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  cat   dog   car  frog\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(vistrainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbi5Coom_tYg"
      },
      "source": [
        "## Define a Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PgAq7r5G_tYg"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(3*32*32, 128)\n",
        "        self.fc2 = nn.Linear(128, 256)\n",
        "        self.fc3 = nn.Linear(256, 512)\n",
        "        self.fc4 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "fc_net = NeuralNet()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRDVTlwx_tYh"
      },
      "source": [
        "## Define a Loss function and optimizer\n",
        "\n",
        "Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lFqlx2aF_tYh"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def get_optimizer(net, lr):\n",
        "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
        "    return optimizer\n",
        "\n",
        "def accuracy(output, target):\n",
        "    # get the index of the max log-probability\n",
        "    pred = output.max(1, keepdim=True)[1]\n",
        "    return pred.eq(target.view_as(pred)).float().mean()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = get_optimizer(fc_net, 0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LvV0YBi_tYi"
      },
      "source": [
        "## Define training code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "znPmfV7x_tYi"
      },
      "outputs": [],
      "source": [
        "def forward_step(net, inputs, labels):\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    return outputs, loss, labels\n",
        "\n",
        "\n",
        "def train(net, loader, optimizer, max_epoch):\n",
        "    net.train()\n",
        "    N = len(loader)\n",
        "    print_interval = (N // 8 // 100 + 1) * 100\n",
        "    for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        for i, data in enumerate(loader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs, loss, labels = forward_step(net, inputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            running_acc += accuracy(outputs, labels).item()\n",
        "            if (i + 1) % print_interval == 0:\n",
        "                print('Epoch: [%d / %d], batches: [%d / %d], loss: %.3f, acc: %.2f' %\n",
        "                      (epoch + 1, max_epoch, i + 1, N,\n",
        "                       running_loss / print_interval, 100 * running_acc / print_interval))\n",
        "                running_loss = 0.0\n",
        "                running_acc = 0.0\n",
        "\n",
        "    print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWlTPJQw_tYj"
      },
      "source": [
        "## Training on GPU?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrjYtIUy_tYj",
        "outputId": "1691458e-7d45-4a5a-bec7-5d808f257032"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59YLaI2Q_tYj"
      },
      "source": [
        "The rest of this section assumes that ``device`` is a CUDA device."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRq08Ret_tYk"
      },
      "source": [
        "## Train the network\n",
        "\n",
        "This is when things start to get interesting.\n",
        "We simply have to loop over our data iterator, and feed the inputs to the\n",
        "network and optimize.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HqDIylo_tYk",
        "outputId": "73aae488-05a3-4c0c-d0c5-23a9db038555"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1 / 5], batches: [100 / 782], loss: 2.211, acc: 19.31\n",
            "Epoch: [1 / 5], batches: [200 / 782], loss: 1.918, acc: 30.48\n",
            "Epoch: [1 / 5], batches: [300 / 782], loss: 1.768, acc: 36.08\n",
            "Epoch: [1 / 5], batches: [400 / 782], loss: 1.708, acc: 38.33\n",
            "Epoch: [1 / 5], batches: [500 / 782], loss: 1.665, acc: 40.33\n",
            "Epoch: [1 / 5], batches: [600 / 782], loss: 1.637, acc: 41.44\n",
            "Epoch: [1 / 5], batches: [700 / 782], loss: 1.593, acc: 43.11\n",
            "Epoch: [2 / 5], batches: [100 / 782], loss: 1.529, acc: 45.75\n",
            "Epoch: [2 / 5], batches: [200 / 782], loss: 1.511, acc: 46.86\n",
            "Epoch: [2 / 5], batches: [300 / 782], loss: 1.498, acc: 46.55\n",
            "Epoch: [2 / 5], batches: [400 / 782], loss: 1.504, acc: 46.27\n",
            "Epoch: [2 / 5], batches: [500 / 782], loss: 1.449, acc: 48.09\n",
            "Epoch: [2 / 5], batches: [600 / 782], loss: 1.460, acc: 48.06\n",
            "Epoch: [2 / 5], batches: [700 / 782], loss: 1.459, acc: 47.33\n",
            "Epoch: [3 / 5], batches: [100 / 782], loss: 1.383, acc: 50.55\n",
            "Epoch: [3 / 5], batches: [200 / 782], loss: 1.386, acc: 50.67\n",
            "Epoch: [3 / 5], batches: [300 / 782], loss: 1.389, acc: 51.17\n",
            "Epoch: [3 / 5], batches: [400 / 782], loss: 1.365, acc: 50.80\n",
            "Epoch: [3 / 5], batches: [500 / 782], loss: 1.341, acc: 51.77\n",
            "Epoch: [3 / 5], batches: [600 / 782], loss: 1.356, acc: 51.94\n",
            "Epoch: [3 / 5], batches: [700 / 782], loss: 1.380, acc: 51.41\n",
            "Epoch: [4 / 5], batches: [100 / 782], loss: 1.252, acc: 56.06\n",
            "Epoch: [4 / 5], batches: [200 / 782], loss: 1.266, acc: 55.14\n",
            "Epoch: [4 / 5], batches: [300 / 782], loss: 1.300, acc: 54.02\n",
            "Epoch: [4 / 5], batches: [400 / 782], loss: 1.282, acc: 54.62\n",
            "Epoch: [4 / 5], batches: [500 / 782], loss: 1.300, acc: 54.55\n",
            "Epoch: [4 / 5], batches: [600 / 782], loss: 1.296, acc: 54.05\n",
            "Epoch: [4 / 5], batches: [700 / 782], loss: 1.269, acc: 54.88\n",
            "Epoch: [5 / 5], batches: [100 / 782], loss: 1.209, acc: 57.62\n",
            "Epoch: [5 / 5], batches: [200 / 782], loss: 1.215, acc: 56.89\n",
            "Epoch: [5 / 5], batches: [300 / 782], loss: 1.190, acc: 57.34\n",
            "Epoch: [5 / 5], batches: [400 / 782], loss: 1.206, acc: 57.47\n",
            "Epoch: [5 / 5], batches: [500 / 782], loss: 1.214, acc: 57.36\n",
            "Epoch: [5 / 5], batches: [600 / 782], loss: 1.210, acc: 57.50\n",
            "Epoch: [5 / 5], batches: [700 / 782], loss: 1.234, acc: 55.59\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "train(fc_net, trainloader, optimizer, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em9vYL3U_tYk"
      },
      "source": [
        "## Let's quickly save our trained model:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oFS9R-Wx_tYk"
      },
      "outputs": [],
      "source": [
        "PATH = './Assignment 1 - Image Classification'\n",
        "\n",
        "def save_model(net, path):\n",
        "    torch.save(net.state_dict(), path)\n",
        "\n",
        "save_model(fc_net, PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvhDOWsB_tYl"
      },
      "source": [
        "## Test the network on the test data\n",
        "\n",
        "\n",
        "We have trained the network for 2 passes over the training dataset.\n",
        "But we need to check if the network has learnt anything at all.\n",
        "\n",
        "We will check this by predicting the class label that the neural network\n",
        "outputs, and checking it against the ground-truth. If the prediction is\n",
        "correct, we add the sample to the list of correct predictions.\n",
        "\n",
        "Okay, first step. Let us display an image from the test set to get familiar.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "CnqJRbBx_tYl",
        "outputId": "cb729ff1-4995-4309-e1cb-40441072049b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GroundTruth:    cat  ship  ship plane\n"
          ]
        }
      ],
      "source": [
        "dataiter = iter(vistestloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4At4s4-M_tYl"
      },
      "source": [
        "## Load a model\n",
        "Next, let's load back in our saved model (note: saving and re-loading the model\n",
        "wasn't necessary here, we only did it to illustrate how to do so):\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0j2WpiS_tYm",
        "outputId": "ea02055d-f857-4ca6-c9e3-e963b1569fdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-5d561a9e3963>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(torch.load(PATH))\n"
          ]
        }
      ],
      "source": [
        "net = NeuralNet()\n",
        "\n",
        "def load_model(net, path):\n",
        "    net.load_state_dict(torch.load(PATH))\n",
        "\n",
        "load_model(net, PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7wjEfBY_tYm"
      },
      "source": [
        "Okay, now let us see what the neural network thinks these examples above are:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZsG9BR-G_tYm"
      },
      "outputs": [],
      "source": [
        "outputs = net(images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdLnwo3j_tYm"
      },
      "source": [
        "The outputs are energies for the 10 classes.\n",
        "The higher the energy for a class, the more the network\n",
        "thinks that the image is of the particular class.\n",
        "So, let's get the index of the highest energy:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "T9Fy7F6U_tYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c85db8cc-51c3-464e-9cb8-1c0147cc942f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted:    cat   cat   cat   cat\n"
          ]
        }
      ],
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mvr4fkYr_tYn"
      },
      "source": [
        "## Define testing code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KBssUocu_tYn"
      },
      "outputs": [],
      "source": [
        "def test(net, testloader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    net.eval()\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            # calculate outputs by running images through the network\n",
        "            outputs = net(images)\n",
        "            # the class with the highest energy is what we choose as prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "        100 * correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GBkzPpO_tYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5645e9d-3d25-41cd-9b55-e993f5b56874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 52 %\n"
          ]
        }
      ],
      "source": [
        "test(net, testloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7s0l3g5h_tYo"
      },
      "source": [
        "## See accuracy of each class\n",
        "\n",
        "That looks way better than chance, which is 10% accuracy (randomly picking\n",
        "a class out of 10 classes).\n",
        "Seems like the network learnt something.\n",
        "\n",
        "Hmmm, what are the classes that performed well, and the classes that did\n",
        "not perform well:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5CSNR8Mu_tYo"
      },
      "outputs": [],
      "source": [
        "def class_test(net, testloader):\n",
        "    # prepare to count predictions for each class\n",
        "    correct_pred = {classname: 0 for classname in classes}\n",
        "    total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "    net.eval()\n",
        "    # again no gradients needed\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            outputs = net(images)\n",
        "            _, predictions = torch.max(outputs, 1)\n",
        "            # collect the correct predictions for each class\n",
        "            for label, prediction in zip(labels, predictions):\n",
        "                if label == prediction:\n",
        "                    correct_pred[classes[label]] += 1\n",
        "                total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "    # print accuracy for each class\n",
        "    for classname, correct_count in correct_pred.items():\n",
        "        acc = 100 * float(correct_count) / total_pred[classname]\n",
        "        print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
        "                                                       acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqkYM0zB_tYo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a79a0dc9-a7dd-41d0-f274-0bcb831c5de8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class plane is: 45.5 %\n",
            "Accuracy for class car   is: 63.8 %\n",
            "Accuracy for class bird  is: 44.5 %\n",
            "Accuracy for class cat   is: 37.2 %\n",
            "Accuracy for class deer  is: 53.0 %\n",
            "Accuracy for class dog   is: 40.2 %\n",
            "Accuracy for class frog  is: 61.8 %\n",
            "Accuracy for class horse is: 49.3 %\n",
            "Accuracy for class ship  is: 69.6 %\n",
            "Accuracy for class truck is: 58.3 %\n"
          ]
        }
      ],
      "source": [
        "class_test(net, testloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1oy_ASO_tYp"
      },
      "source": [
        "# Your turn now!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0rwr3cV_tYp"
      },
      "source": [
        "## Define a Convolutional Neural Network\n",
        "\n",
        "The architecture should be:\n",
        "\n",
        "    conv2d, 5x5, 3->8, padding=2\n",
        "\n",
        "    Relu()\n",
        "\n",
        "    conv2d, 5x5, 8->16, padding=2, stride=2\n",
        "\n",
        "    Relu()\n",
        "\n",
        "    conv2d, 5x5, 16->32, padding=2\n",
        "    \n",
        "    Relu()\n",
        "\n",
        "    conv2d, 5x5, 32->64, padding=2, stride=2\n",
        "    \n",
        "    Relu()\n",
        "\n",
        "    conv2d, 5x5, 64->128, padding=2\n",
        "\n",
        "    maxpool2d\n",
        "\n",
        "    Relu()\n",
        "\n",
        "    flatten the feature map\n",
        "\n",
        "    fc, the whole feature map -> 120\n",
        "\n",
        "    Relu()\n",
        "\n",
        "    fc, 120->84\n",
        "\n",
        "    Relu()\n",
        "\n",
        "    fc, 84->10\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YUo5lESj_tYp"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class ConvolutionNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 8, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(8, 16, kernel_size=5, padding=2, stride=2)\n",
        "        self.conv3 = nn.Conv2d(16, 32, kernel_size=5, padding=2)\n",
        "        self.conv4 = nn.Conv2d(32, 64, kernel_size=5, padding=2, stride=2)\n",
        "        self.conv5 = nn.Conv2d(64, 128, kernel_size=5, padding=2)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        #pass\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = F.relu(self.conv5(x))\n",
        "\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = x.view(-1, 128 * 4 * 4)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        #pass\n",
        "        return x\n",
        "\n",
        "net_conv = ConvolutionNet()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVfSZbTh_tYp"
      },
      "source": [
        "## Train the convolutional neural network\n",
        "\n",
        "Train this CNN with learning rate 1e-2 for 5 epochs.\n",
        "\n",
        "You should see the training loss is aroung 0.9 and accuracy is around 67%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lryWLqI_tYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d0265c3-c4b1-448c-c2c1-8de3c4462a94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1 / 5], batches: [100 / 782], loss: 2.304, acc: 9.28\n",
            "Epoch: [1 / 5], batches: [200 / 782], loss: 2.303, acc: 10.22\n",
            "Epoch: [1 / 5], batches: [300 / 782], loss: 2.303, acc: 10.39\n",
            "Epoch: [1 / 5], batches: [400 / 782], loss: 2.299, acc: 12.36\n",
            "Epoch: [1 / 5], batches: [500 / 782], loss: 2.201, acc: 17.69\n",
            "Epoch: [1 / 5], batches: [600 / 782], loss: 2.072, acc: 23.98\n",
            "Epoch: [1 / 5], batches: [700 / 782], loss: 1.981, acc: 26.17\n",
            "Epoch: [2 / 5], batches: [100 / 782], loss: 1.755, acc: 34.58\n",
            "Epoch: [2 / 5], batches: [200 / 782], loss: 1.678, acc: 37.61\n",
            "Epoch: [2 / 5], batches: [300 / 782], loss: 1.617, acc: 40.06\n",
            "Epoch: [2 / 5], batches: [400 / 782], loss: 1.567, acc: 42.91\n",
            "Epoch: [2 / 5], batches: [500 / 782], loss: 1.524, acc: 44.44\n",
            "Epoch: [2 / 5], batches: [600 / 782], loss: 1.496, acc: 45.56\n",
            "Epoch: [2 / 5], batches: [700 / 782], loss: 1.469, acc: 46.81\n",
            "Epoch: [3 / 5], batches: [100 / 782], loss: 1.392, acc: 49.23\n",
            "Epoch: [3 / 5], batches: [200 / 782], loss: 1.399, acc: 49.22\n",
            "Epoch: [3 / 5], batches: [300 / 782], loss: 1.354, acc: 50.88\n",
            "Epoch: [3 / 5], batches: [400 / 782], loss: 1.301, acc: 53.03\n",
            "Epoch: [3 / 5], batches: [500 / 782], loss: 1.277, acc: 53.73\n",
            "Epoch: [3 / 5], batches: [600 / 782], loss: 1.264, acc: 54.98\n",
            "Epoch: [3 / 5], batches: [700 / 782], loss: 1.245, acc: 55.45\n",
            "Epoch: [4 / 5], batches: [100 / 782], loss: 1.169, acc: 57.84\n",
            "Epoch: [4 / 5], batches: [200 / 782], loss: 1.163, acc: 57.61\n",
            "Epoch: [4 / 5], batches: [300 / 782], loss: 1.164, acc: 58.95\n",
            "Epoch: [4 / 5], batches: [400 / 782], loss: 1.154, acc: 59.38\n",
            "Epoch: [4 / 5], batches: [500 / 782], loss: 1.119, acc: 59.80\n",
            "Epoch: [4 / 5], batches: [600 / 782], loss: 1.111, acc: 60.66\n",
            "Epoch: [4 / 5], batches: [700 / 782], loss: 1.117, acc: 60.48\n",
            "Epoch: [5 / 5], batches: [100 / 782], loss: 1.002, acc: 64.28\n",
            "Epoch: [5 / 5], batches: [200 / 782], loss: 0.981, acc: 64.84\n",
            "Epoch: [5 / 5], batches: [300 / 782], loss: 0.993, acc: 64.72\n",
            "Epoch: [5 / 5], batches: [400 / 782], loss: 0.987, acc: 64.59\n",
            "Epoch: [5 / 5], batches: [500 / 782], loss: 0.997, acc: 64.67\n",
            "Epoch: [5 / 5], batches: [600 / 782], loss: 0.997, acc: 65.45\n",
            "Epoch: [5 / 5], batches: [700 / 782], loss: 0.970, acc: 65.97\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = get_optimizer(net_conv, 0.01)\n",
        "\n",
        "train(net_conv, trainloader, optimizer, 5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(net_conv, PATH)"
      ],
      "metadata": {
        "id": "5QYmOf3aDgt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvHEJIBm_tYq"
      },
      "source": [
        "## Test the convolutional neural network\n",
        "\n",
        "Test this CNN on the test dataset.\n",
        "\n",
        "You should see the accuracy is around 62%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EAKpukP_tYw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "286b40a0-db36-40cc-c9e7-7ae4f472f763"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-5d561a9e3963>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(torch.load(PATH))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 62 %\n"
          ]
        }
      ],
      "source": [
        "net = ConvolutionNet()\n",
        "\n",
        "load_model(net, PATH)\n",
        "\n",
        "test(net, testloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbTiB7BL_tYw"
      },
      "source": [
        "## Accuracy (each class) of CNN\n",
        "\n",
        "Test this CNN on the test dataset to see the accuracy of each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6K3j-x6q_tYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4239d75a-0002-4093-b1af-0e8ca78ef0ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class plane is: 62.1 %\n",
            "Accuracy for class car   is: 78.7 %\n",
            "Accuracy for class bird  is: 49.1 %\n",
            "Accuracy for class cat   is: 26.4 %\n",
            "Accuracy for class deer  is: 54.0 %\n",
            "Accuracy for class dog   is: 54.4 %\n",
            "Accuracy for class frog  is: 84.1 %\n",
            "Accuracy for class horse is: 65.8 %\n",
            "Accuracy for class ship  is: 81.9 %\n",
            "Accuracy for class truck is: 67.8 %\n"
          ]
        }
      ],
      "source": [
        "class_test(net, testloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NknyaagF_tYx"
      },
      "source": [
        "## Let's use BN\n",
        "\n",
        "Add BatchNorm2d to the convolution neural network you implemented.\n",
        "\n",
        "You should add batchnorm after the convolution operator and before the activation layer.\n",
        "\n",
        "Please train this network and show the test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xx4oaioj_tYx"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvolutionBNNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 8, kernel_size=5, padding=2)\n",
        "        self.bn1 = nn.BatchNorm2d(8)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(8, 16, kernel_size=5, padding=2, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(16)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(16, 32, kernel_size=5, padding=2)\n",
        "        self.bn3 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(32, 64, kernel_size=5, padding=2, stride=2)\n",
        "        self.bn4 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(64, 128, kernel_size=5, padding=2)\n",
        "        self.bn5 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        #pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = F.relu(self.bn5(self.conv5(x)))\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = x.view(-1, 128 * 4 * 4)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        #pass\n",
        "        return x\n",
        "\n",
        "net_conv_bn = ConvolutionBNNet()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7Y1u8Z1_tYx"
      },
      "source": [
        "## Train the CNN with BN\n",
        "\n",
        "Train this CNN with learning rate 1e-2 for 5 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enziLIf-_tYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75fd46d0-b663-419c-9b08-10cc266d1801"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1 / 5], batches: [100 / 782], loss: 1.984, acc: 24.83\n",
            "Epoch: [1 / 5], batches: [200 / 782], loss: 1.678, acc: 37.08\n",
            "Epoch: [1 / 5], batches: [300 / 782], loss: 1.526, acc: 44.31\n",
            "Epoch: [1 / 5], batches: [400 / 782], loss: 1.464, acc: 46.78\n",
            "Epoch: [1 / 5], batches: [500 / 782], loss: 1.378, acc: 49.78\n",
            "Epoch: [1 / 5], batches: [600 / 782], loss: 1.341, acc: 51.94\n",
            "Epoch: [1 / 5], batches: [700 / 782], loss: 1.241, acc: 55.41\n",
            "Epoch: [2 / 5], batches: [100 / 782], loss: 1.163, acc: 58.06\n",
            "Epoch: [2 / 5], batches: [200 / 782], loss: 1.106, acc: 60.23\n",
            "Epoch: [2 / 5], batches: [300 / 782], loss: 1.089, acc: 60.64\n",
            "Epoch: [2 / 5], batches: [400 / 782], loss: 1.045, acc: 62.47\n",
            "Epoch: [2 / 5], batches: [500 / 782], loss: 1.023, acc: 62.97\n",
            "Epoch: [2 / 5], batches: [600 / 782], loss: 1.007, acc: 64.48\n",
            "Epoch: [2 / 5], batches: [700 / 782], loss: 0.967, acc: 65.72\n",
            "Epoch: [3 / 5], batches: [100 / 782], loss: 0.869, acc: 69.05\n",
            "Epoch: [3 / 5], batches: [200 / 782], loss: 0.852, acc: 70.06\n",
            "Epoch: [3 / 5], batches: [300 / 782], loss: 0.843, acc: 70.09\n",
            "Epoch: [3 / 5], batches: [400 / 782], loss: 0.807, acc: 71.50\n",
            "Epoch: [3 / 5], batches: [500 / 782], loss: 0.826, acc: 71.28\n",
            "Epoch: [3 / 5], batches: [600 / 782], loss: 0.811, acc: 70.95\n",
            "Epoch: [3 / 5], batches: [700 / 782], loss: 0.794, acc: 72.16\n",
            "Epoch: [4 / 5], batches: [100 / 782], loss: 0.704, acc: 75.39\n",
            "Epoch: [4 / 5], batches: [200 / 782], loss: 0.659, acc: 77.34\n",
            "Epoch: [4 / 5], batches: [300 / 782], loss: 0.707, acc: 75.52\n",
            "Epoch: [4 / 5], batches: [400 / 782], loss: 0.689, acc: 75.39\n",
            "Epoch: [4 / 5], batches: [500 / 782], loss: 0.693, acc: 75.91\n",
            "Epoch: [4 / 5], batches: [600 / 782], loss: 0.682, acc: 75.78\n",
            "Epoch: [4 / 5], batches: [700 / 782], loss: 0.700, acc: 75.70\n",
            "Epoch: [5 / 5], batches: [100 / 782], loss: 0.587, acc: 79.20\n",
            "Epoch: [5 / 5], batches: [200 / 782], loss: 0.580, acc: 80.16\n",
            "Epoch: [5 / 5], batches: [300 / 782], loss: 0.575, acc: 79.80\n",
            "Epoch: [5 / 5], batches: [400 / 782], loss: 0.631, acc: 77.70\n",
            "Epoch: [5 / 5], batches: [500 / 782], loss: 0.610, acc: 78.38\n",
            "Epoch: [5 / 5], batches: [600 / 782], loss: 0.598, acc: 79.53\n",
            "Epoch: [5 / 5], batches: [700 / 782], loss: 0.592, acc: 79.31\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "#pass\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = get_optimizer(net_conv_bn, 0.01)\n",
        "\n",
        "train(net_conv_bn, trainloader, optimizer, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-M3tQBq_tYy"
      },
      "source": [
        "## Test the CNN with BN\n",
        "\n",
        "Test this CNN on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecRtP_MI_tYy"
      },
      "outputs": [],
      "source": [
        "save_model(net_conv_bn, PATH)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = ConvolutionBNNet()\n",
        "\n",
        "load_model(net, PATH)\n",
        "\n",
        "test(net, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35dDg9eKRdEV",
        "outputId": "b7e55933-6b2b-4a4c-c8f5-2c7641b6a062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-5d561a9e3963>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(torch.load(PATH))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 74 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2PPX-cd_tYy"
      },
      "source": [
        "## Accuracy (each class) of CNN with BN\n",
        "\n",
        "Test this CNN with BNN on the test dataset to see the accuracy of each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J69murTS_tYz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55260e09-f416-4ecc-aaf7-852884a73d58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class plane is: 84.7 %\n",
            "Accuracy for class car   is: 92.0 %\n",
            "Accuracy for class bird  is: 66.5 %\n",
            "Accuracy for class cat   is: 62.8 %\n",
            "Accuracy for class deer  is: 60.4 %\n",
            "Accuracy for class dog   is: 49.7 %\n",
            "Accuracy for class frog  is: 88.6 %\n",
            "Accuracy for class horse is: 79.0 %\n",
            "Accuracy for class ship  is: 85.2 %\n",
            "Accuracy for class truck is: 77.9 %\n"
          ]
        }
      ],
      "source": [
        "class_test(net, testloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAh1Vhh-_tYz"
      },
      "source": [
        "## Design by yourself\n",
        "Now, based on the knowledge learned in class or by referring to online resources, you can design your own network architecture or incorporate other optimization methods to improve task performance. Please provide at least one improvement strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build CNN with updated kernel size, BN and Dropout Regularization\n",
        "\n",
        "Update Kernel size and add Dropout Regularization to the convolution neural network."
      ],
      "metadata": {
        "id": "2vDJ96ZFdWHq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eopAF638_tYz"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvolutionNetNew(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvolutionNetNew, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 8, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(8)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(16)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(32, 64, kernel_size=3, padding=1, stride=2)\n",
        "        self.bn4 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = F.relu(self.bn5(self.conv5(x)))\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "net_conv_new = ConvolutionNetNew()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Update the optimizer\n",
        "\n",
        "Update the optimizer uisng Adam."
      ],
      "metadata": {
        "id": "NDrbYsgUeN45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def get_optimizer_adam(net, lr):\n",
        "    optimizer = optim.Adam(net.parameters(), lr=lr, betas=(0.9, 0.999))\n",
        "    return optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = get_optimizer_adam(net_conv_new, 0.001)"
      ],
      "metadata": {
        "id": "R_eQywB8cj7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the CNN with BN, Dropout Regularization and Leaky ReLU"
      ],
      "metadata": {
        "id": "da6fY9l7fTCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(net_conv_new, trainloader, optimizer, 15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XflWI1YMfTWN",
        "outputId": "1e508f86-226e-45cd-ceaf-8f19cde4eb4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1 / 15], batches: [100 / 782], loss: 1.903, acc: 29.11\n",
            "Epoch: [1 / 15], batches: [200 / 782], loss: 1.568, acc: 42.23\n",
            "Epoch: [1 / 15], batches: [300 / 782], loss: 1.431, acc: 46.69\n",
            "Epoch: [1 / 15], batches: [400 / 782], loss: 1.355, acc: 51.23\n",
            "Epoch: [1 / 15], batches: [500 / 782], loss: 1.258, acc: 53.75\n",
            "Epoch: [1 / 15], batches: [600 / 782], loss: 1.216, acc: 56.53\n",
            "Epoch: [1 / 15], batches: [700 / 782], loss: 1.151, acc: 58.97\n",
            "Epoch: [2 / 15], batches: [100 / 782], loss: 1.018, acc: 63.80\n",
            "Epoch: [2 / 15], batches: [200 / 782], loss: 1.015, acc: 64.17\n",
            "Epoch: [2 / 15], batches: [300 / 782], loss: 1.011, acc: 63.72\n",
            "Epoch: [2 / 15], batches: [400 / 782], loss: 0.966, acc: 66.09\n",
            "Epoch: [2 / 15], batches: [500 / 782], loss: 0.964, acc: 66.42\n",
            "Epoch: [2 / 15], batches: [600 / 782], loss: 0.932, acc: 67.55\n",
            "Epoch: [2 / 15], batches: [700 / 782], loss: 0.933, acc: 66.39\n",
            "Epoch: [3 / 15], batches: [100 / 782], loss: 0.823, acc: 71.36\n",
            "Epoch: [3 / 15], batches: [200 / 782], loss: 0.837, acc: 70.47\n",
            "Epoch: [3 / 15], batches: [300 / 782], loss: 0.821, acc: 71.48\n",
            "Epoch: [3 / 15], batches: [400 / 782], loss: 0.828, acc: 71.22\n",
            "Epoch: [3 / 15], batches: [500 / 782], loss: 0.800, acc: 72.23\n",
            "Epoch: [3 / 15], batches: [600 / 782], loss: 0.788, acc: 72.70\n",
            "Epoch: [3 / 15], batches: [700 / 782], loss: 0.800, acc: 72.12\n",
            "Epoch: [4 / 15], batches: [100 / 782], loss: 0.692, acc: 75.44\n",
            "Epoch: [4 / 15], batches: [200 / 782], loss: 0.711, acc: 75.69\n",
            "Epoch: [4 / 15], batches: [300 / 782], loss: 0.721, acc: 74.31\n",
            "Epoch: [4 / 15], batches: [400 / 782], loss: 0.716, acc: 75.42\n",
            "Epoch: [4 / 15], batches: [500 / 782], loss: 0.703, acc: 75.02\n",
            "Epoch: [4 / 15], batches: [600 / 782], loss: 0.711, acc: 75.41\n",
            "Epoch: [4 / 15], batches: [700 / 782], loss: 0.693, acc: 75.69\n",
            "Epoch: [5 / 15], batches: [100 / 782], loss: 0.622, acc: 78.41\n",
            "Epoch: [5 / 15], batches: [200 / 782], loss: 0.610, acc: 78.73\n",
            "Epoch: [5 / 15], batches: [300 / 782], loss: 0.623, acc: 78.61\n",
            "Epoch: [5 / 15], batches: [400 / 782], loss: 0.599, acc: 78.53\n",
            "Epoch: [5 / 15], batches: [500 / 782], loss: 0.629, acc: 77.77\n",
            "Epoch: [5 / 15], batches: [600 / 782], loss: 0.616, acc: 78.44\n",
            "Epoch: [5 / 15], batches: [700 / 782], loss: 0.652, acc: 77.34\n",
            "Epoch: [6 / 15], batches: [100 / 782], loss: 0.523, acc: 81.72\n",
            "Epoch: [6 / 15], batches: [200 / 782], loss: 0.529, acc: 81.02\n",
            "Epoch: [6 / 15], batches: [300 / 782], loss: 0.557, acc: 80.77\n",
            "Epoch: [6 / 15], batches: [400 / 782], loss: 0.530, acc: 81.58\n",
            "Epoch: [6 / 15], batches: [500 / 782], loss: 0.539, acc: 81.22\n",
            "Epoch: [6 / 15], batches: [600 / 782], loss: 0.570, acc: 80.33\n",
            "Epoch: [6 / 15], batches: [700 / 782], loss: 0.554, acc: 81.11\n",
            "Epoch: [7 / 15], batches: [100 / 782], loss: 0.449, acc: 84.23\n",
            "Epoch: [7 / 15], batches: [200 / 782], loss: 0.458, acc: 83.67\n",
            "Epoch: [7 / 15], batches: [300 / 782], loss: 0.465, acc: 84.14\n",
            "Epoch: [7 / 15], batches: [400 / 782], loss: 0.483, acc: 82.95\n",
            "Epoch: [7 / 15], batches: [500 / 782], loss: 0.480, acc: 83.11\n",
            "Epoch: [7 / 15], batches: [600 / 782], loss: 0.489, acc: 82.89\n",
            "Epoch: [7 / 15], batches: [700 / 782], loss: 0.490, acc: 83.02\n",
            "Epoch: [8 / 15], batches: [100 / 782], loss: 0.388, acc: 86.62\n",
            "Epoch: [8 / 15], batches: [200 / 782], loss: 0.392, acc: 86.48\n",
            "Epoch: [8 / 15], batches: [300 / 782], loss: 0.405, acc: 86.00\n",
            "Epoch: [8 / 15], batches: [400 / 782], loss: 0.418, acc: 85.70\n",
            "Epoch: [8 / 15], batches: [500 / 782], loss: 0.413, acc: 85.84\n",
            "Epoch: [8 / 15], batches: [600 / 782], loss: 0.429, acc: 85.25\n",
            "Epoch: [8 / 15], batches: [700 / 782], loss: 0.442, acc: 84.56\n",
            "Epoch: [9 / 15], batches: [100 / 782], loss: 0.303, acc: 89.75\n",
            "Epoch: [9 / 15], batches: [200 / 782], loss: 0.336, acc: 88.12\n",
            "Epoch: [9 / 15], batches: [300 / 782], loss: 0.361, acc: 87.50\n",
            "Epoch: [9 / 15], batches: [400 / 782], loss: 0.381, acc: 86.86\n",
            "Epoch: [9 / 15], batches: [500 / 782], loss: 0.375, acc: 87.09\n",
            "Epoch: [9 / 15], batches: [600 / 782], loss: 0.375, acc: 86.61\n",
            "Epoch: [9 / 15], batches: [700 / 782], loss: 0.394, acc: 86.23\n",
            "Epoch: [10 / 15], batches: [100 / 782], loss: 0.269, acc: 90.69\n",
            "Epoch: [10 / 15], batches: [200 / 782], loss: 0.281, acc: 90.50\n",
            "Epoch: [10 / 15], batches: [300 / 782], loss: 0.313, acc: 89.27\n",
            "Epoch: [10 / 15], batches: [400 / 782], loss: 0.305, acc: 89.20\n",
            "Epoch: [10 / 15], batches: [500 / 782], loss: 0.314, acc: 89.06\n",
            "Epoch: [10 / 15], batches: [600 / 782], loss: 0.346, acc: 88.27\n",
            "Epoch: [10 / 15], batches: [700 / 782], loss: 0.328, acc: 88.34\n",
            "Epoch: [11 / 15], batches: [100 / 782], loss: 0.224, acc: 92.25\n",
            "Epoch: [11 / 15], batches: [200 / 782], loss: 0.242, acc: 91.70\n",
            "Epoch: [11 / 15], batches: [300 / 782], loss: 0.252, acc: 91.41\n",
            "Epoch: [11 / 15], batches: [400 / 782], loss: 0.258, acc: 90.95\n",
            "Epoch: [11 / 15], batches: [500 / 782], loss: 0.303, acc: 89.56\n",
            "Epoch: [11 / 15], batches: [600 / 782], loss: 0.291, acc: 89.98\n",
            "Epoch: [11 / 15], batches: [700 / 782], loss: 0.278, acc: 90.12\n",
            "Epoch: [12 / 15], batches: [100 / 782], loss: 0.195, acc: 93.19\n",
            "Epoch: [12 / 15], batches: [200 / 782], loss: 0.211, acc: 92.92\n",
            "Epoch: [12 / 15], batches: [300 / 782], loss: 0.228, acc: 91.95\n",
            "Epoch: [12 / 15], batches: [400 / 782], loss: 0.255, acc: 91.02\n",
            "Epoch: [12 / 15], batches: [500 / 782], loss: 0.246, acc: 91.72\n",
            "Epoch: [12 / 15], batches: [600 / 782], loss: 0.277, acc: 90.56\n",
            "Epoch: [12 / 15], batches: [700 / 782], loss: 0.251, acc: 91.14\n",
            "Epoch: [13 / 15], batches: [100 / 782], loss: 0.162, acc: 94.17\n",
            "Epoch: [13 / 15], batches: [200 / 782], loss: 0.180, acc: 93.92\n",
            "Epoch: [13 / 15], batches: [300 / 782], loss: 0.226, acc: 92.16\n",
            "Epoch: [13 / 15], batches: [400 / 782], loss: 0.208, acc: 92.83\n",
            "Epoch: [13 / 15], batches: [500 / 782], loss: 0.214, acc: 92.45\n",
            "Epoch: [13 / 15], batches: [600 / 782], loss: 0.227, acc: 92.09\n",
            "Epoch: [13 / 15], batches: [700 / 782], loss: 0.253, acc: 91.48\n",
            "Epoch: [14 / 15], batches: [100 / 782], loss: 0.151, acc: 94.58\n",
            "Epoch: [14 / 15], batches: [200 / 782], loss: 0.156, acc: 94.59\n",
            "Epoch: [14 / 15], batches: [300 / 782], loss: 0.185, acc: 93.52\n",
            "Epoch: [14 / 15], batches: [400 / 782], loss: 0.175, acc: 93.97\n",
            "Epoch: [14 / 15], batches: [500 / 782], loss: 0.199, acc: 93.39\n",
            "Epoch: [14 / 15], batches: [600 / 782], loss: 0.198, acc: 93.36\n",
            "Epoch: [14 / 15], batches: [700 / 782], loss: 0.212, acc: 92.66\n",
            "Epoch: [15 / 15], batches: [100 / 782], loss: 0.125, acc: 95.44\n",
            "Epoch: [15 / 15], batches: [200 / 782], loss: 0.118, acc: 96.05\n",
            "Epoch: [15 / 15], batches: [300 / 782], loss: 0.159, acc: 94.48\n",
            "Epoch: [15 / 15], batches: [400 / 782], loss: 0.150, acc: 94.75\n",
            "Epoch: [15 / 15], batches: [500 / 782], loss: 0.187, acc: 93.78\n",
            "Epoch: [15 / 15], batches: [600 / 782], loss: 0.177, acc: 93.89\n",
            "Epoch: [15 / 15], batches: [700 / 782], loss: 0.173, acc: 93.92\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the CNN with BN, Dropout Regularization and Leaky ReLU\n",
        "\n",
        "Test this CNN on the test dataset."
      ],
      "metadata": {
        "id": "FdzJ0cpAfnoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(net_conv_new, PATH)"
      ],
      "metadata": {
        "id": "slRRCxpGfrQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = ConvolutionNetNew()\n",
        "\n",
        "load_model(net, PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaBoqbYFfwgj",
        "outputId": "1e580fbd-8af8-4ed5-e489-9a73025e3ab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-5d561a9e3963>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(torch.load(PATH))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(net, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDyeh1iYHi9Q",
        "outputId": "78267094-c1dc-44ad-ae13-9ce96b636720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 75 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy (each class) of the updated CNN\n",
        "\n",
        "Test this updated CNN on the test dataset to see the accuracy of each class."
      ],
      "metadata": {
        "id": "lqd9zYqyf2aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_test(net, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3VWaMpAf3Jg",
        "outputId": "a598970c-aaf2-440a-f346-24bff9fccb17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class plane is: 83.4 %\n",
            "Accuracy for class car   is: 87.4 %\n",
            "Accuracy for class bird  is: 57.5 %\n",
            "Accuracy for class cat   is: 51.0 %\n",
            "Accuracy for class deer  is: 66.6 %\n",
            "Accuracy for class dog   is: 67.9 %\n",
            "Accuracy for class frog  is: 84.0 %\n",
            "Accuracy for class horse is: 78.7 %\n",
            "Accuracy for class ship  is: 88.5 %\n",
            "Accuracy for class truck is: 86.2 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alterntive: VGG Block"
      ],
      "metadata": {
        "id": "y0Ye5Y3OnDTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout1 = nn.Dropout(p=0.2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(64)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout2 = nn.Dropout(p=0.3)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(128)\n",
        "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn6 = nn.BatchNorm2d(128)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout3 = nn.Dropout(p=0.4)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n",
        "        self.bn7 = nn.BatchNorm1d(128)\n",
        "        self.dropout4 = nn.Dropout(p=0.5)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.pool2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = F.relu(self.bn5(self.conv5(x)))\n",
        "        x = F.relu(self.bn6(self.conv6(x)))\n",
        "        x = self.pool3(x)\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.bn7(self.fc1(x)))\n",
        "        x = self.dropout4(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "vgg = VGG()"
      ],
      "metadata": {
        "id": "8EP-ChU4jhHr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def get_optimizer_adam(net, lr):\n",
        "    optimizer = optim.Adam(net.parameters(), lr=lr, betas=(0.9, 0.999))\n",
        "    return optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = get_optimizer_adam(vgg, 0.001)"
      ],
      "metadata": {
        "id": "qma4jLTcjhAf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(vgg, trainloader, optimizer, 15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKYJTrbnjg3X",
        "outputId": "ce4041a5-4f49-4060-d6d2-6e79537c1586"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1 / 15], batches: [100 / 782], loss: 1.869, acc: 31.47\n",
            "Epoch: [1 / 15], batches: [200 / 782], loss: 1.540, acc: 44.17\n",
            "Epoch: [1 / 15], batches: [300 / 782], loss: 1.407, acc: 48.97\n",
            "Epoch: [1 / 15], batches: [400 / 782], loss: 1.307, acc: 53.19\n",
            "Epoch: [1 / 15], batches: [500 / 782], loss: 1.239, acc: 55.70\n",
            "Epoch: [1 / 15], batches: [600 / 782], loss: 1.186, acc: 57.55\n",
            "Epoch: [1 / 15], batches: [700 / 782], loss: 1.128, acc: 60.03\n",
            "Epoch: [2 / 15], batches: [100 / 782], loss: 1.041, acc: 63.19\n",
            "Epoch: [2 / 15], batches: [200 / 782], loss: 1.024, acc: 63.62\n",
            "Epoch: [2 / 15], batches: [300 / 782], loss: 1.022, acc: 64.31\n",
            "Epoch: [2 / 15], batches: [400 / 782], loss: 0.985, acc: 65.48\n",
            "Epoch: [2 / 15], batches: [500 / 782], loss: 0.928, acc: 68.03\n",
            "Epoch: [2 / 15], batches: [600 / 782], loss: 0.924, acc: 68.27\n",
            "Epoch: [2 / 15], batches: [700 / 782], loss: 0.899, acc: 68.28\n",
            "Epoch: [3 / 15], batches: [100 / 782], loss: 0.855, acc: 70.62\n",
            "Epoch: [3 / 15], batches: [200 / 782], loss: 0.849, acc: 70.33\n",
            "Epoch: [3 / 15], batches: [300 / 782], loss: 0.845, acc: 70.50\n",
            "Epoch: [3 / 15], batches: [400 / 782], loss: 0.843, acc: 70.28\n",
            "Epoch: [3 / 15], batches: [500 / 782], loss: 0.846, acc: 70.70\n",
            "Epoch: [3 / 15], batches: [600 / 782], loss: 0.830, acc: 71.22\n",
            "Epoch: [3 / 15], batches: [700 / 782], loss: 0.819, acc: 71.16\n",
            "Epoch: [4 / 15], batches: [100 / 782], loss: 0.784, acc: 72.89\n",
            "Epoch: [4 / 15], batches: [200 / 782], loss: 0.774, acc: 73.16\n",
            "Epoch: [4 / 15], batches: [300 / 782], loss: 0.742, acc: 74.73\n",
            "Epoch: [4 / 15], batches: [400 / 782], loss: 0.774, acc: 73.27\n",
            "Epoch: [4 / 15], batches: [500 / 782], loss: 0.765, acc: 73.88\n",
            "Epoch: [4 / 15], batches: [600 / 782], loss: 0.749, acc: 73.97\n",
            "Epoch: [4 / 15], batches: [700 / 782], loss: 0.742, acc: 74.28\n",
            "Epoch: [5 / 15], batches: [100 / 782], loss: 0.691, acc: 76.02\n",
            "Epoch: [5 / 15], batches: [200 / 782], loss: 0.698, acc: 75.95\n",
            "Epoch: [5 / 15], batches: [300 / 782], loss: 0.724, acc: 75.19\n",
            "Epoch: [5 / 15], batches: [400 / 782], loss: 0.719, acc: 75.94\n",
            "Epoch: [5 / 15], batches: [500 / 782], loss: 0.695, acc: 76.00\n",
            "Epoch: [5 / 15], batches: [600 / 782], loss: 0.692, acc: 76.00\n",
            "Epoch: [5 / 15], batches: [700 / 782], loss: 0.696, acc: 76.50\n",
            "Epoch: [6 / 15], batches: [100 / 782], loss: 0.656, acc: 77.59\n",
            "Epoch: [6 / 15], batches: [200 / 782], loss: 0.634, acc: 77.78\n",
            "Epoch: [6 / 15], batches: [300 / 782], loss: 0.657, acc: 77.72\n",
            "Epoch: [6 / 15], batches: [400 / 782], loss: 0.645, acc: 78.08\n",
            "Epoch: [6 / 15], batches: [500 / 782], loss: 0.661, acc: 77.47\n",
            "Epoch: [6 / 15], batches: [600 / 782], loss: 0.671, acc: 76.67\n",
            "Epoch: [6 / 15], batches: [700 / 782], loss: 0.639, acc: 78.41\n",
            "Epoch: [7 / 15], batches: [100 / 782], loss: 0.602, acc: 79.06\n",
            "Epoch: [7 / 15], batches: [200 / 782], loss: 0.608, acc: 78.83\n",
            "Epoch: [7 / 15], batches: [300 / 782], loss: 0.617, acc: 78.34\n",
            "Epoch: [7 / 15], batches: [400 / 782], loss: 0.628, acc: 78.84\n",
            "Epoch: [7 / 15], batches: [500 / 782], loss: 0.617, acc: 78.81\n",
            "Epoch: [7 / 15], batches: [600 / 782], loss: 0.625, acc: 78.77\n",
            "Epoch: [7 / 15], batches: [700 / 782], loss: 0.591, acc: 79.78\n",
            "Epoch: [8 / 15], batches: [100 / 782], loss: 0.568, acc: 80.91\n",
            "Epoch: [8 / 15], batches: [200 / 782], loss: 0.584, acc: 80.28\n",
            "Epoch: [8 / 15], batches: [300 / 782], loss: 0.579, acc: 79.91\n",
            "Epoch: [8 / 15], batches: [400 / 782], loss: 0.588, acc: 79.55\n",
            "Epoch: [8 / 15], batches: [500 / 782], loss: 0.586, acc: 80.28\n",
            "Epoch: [8 / 15], batches: [600 / 782], loss: 0.579, acc: 80.78\n",
            "Epoch: [8 / 15], batches: [700 / 782], loss: 0.571, acc: 80.80\n",
            "Epoch: [9 / 15], batches: [100 / 782], loss: 0.541, acc: 81.39\n",
            "Epoch: [9 / 15], batches: [200 / 782], loss: 0.534, acc: 81.62\n",
            "Epoch: [9 / 15], batches: [300 / 782], loss: 0.536, acc: 81.52\n",
            "Epoch: [9 / 15], batches: [400 / 782], loss: 0.564, acc: 80.62\n",
            "Epoch: [9 / 15], batches: [500 / 782], loss: 0.553, acc: 81.36\n",
            "Epoch: [9 / 15], batches: [600 / 782], loss: 0.540, acc: 81.75\n",
            "Epoch: [9 / 15], batches: [700 / 782], loss: 0.551, acc: 81.22\n",
            "Epoch: [10 / 15], batches: [100 / 782], loss: 0.523, acc: 82.20\n",
            "Epoch: [10 / 15], batches: [200 / 782], loss: 0.530, acc: 82.50\n",
            "Epoch: [10 / 15], batches: [300 / 782], loss: 0.522, acc: 82.11\n",
            "Epoch: [10 / 15], batches: [400 / 782], loss: 0.543, acc: 81.19\n",
            "Epoch: [10 / 15], batches: [500 / 782], loss: 0.521, acc: 82.31\n",
            "Epoch: [10 / 15], batches: [600 / 782], loss: 0.526, acc: 82.36\n",
            "Epoch: [10 / 15], batches: [700 / 782], loss: 0.504, acc: 82.62\n",
            "Epoch: [11 / 15], batches: [100 / 782], loss: 0.493, acc: 83.19\n",
            "Epoch: [11 / 15], batches: [200 / 782], loss: 0.494, acc: 83.25\n",
            "Epoch: [11 / 15], batches: [300 / 782], loss: 0.467, acc: 83.84\n",
            "Epoch: [11 / 15], batches: [400 / 782], loss: 0.511, acc: 82.31\n",
            "Epoch: [11 / 15], batches: [500 / 782], loss: 0.511, acc: 82.70\n",
            "Epoch: [11 / 15], batches: [600 / 782], loss: 0.501, acc: 83.33\n",
            "Epoch: [11 / 15], batches: [700 / 782], loss: 0.515, acc: 82.62\n",
            "Epoch: [12 / 15], batches: [100 / 782], loss: 0.451, acc: 83.94\n",
            "Epoch: [12 / 15], batches: [200 / 782], loss: 0.478, acc: 83.75\n",
            "Epoch: [12 / 15], batches: [300 / 782], loss: 0.454, acc: 84.45\n",
            "Epoch: [12 / 15], batches: [400 / 782], loss: 0.500, acc: 83.22\n",
            "Epoch: [12 / 15], batches: [500 / 782], loss: 0.495, acc: 83.42\n",
            "Epoch: [12 / 15], batches: [600 / 782], loss: 0.491, acc: 83.50\n",
            "Epoch: [12 / 15], batches: [700 / 782], loss: 0.471, acc: 83.36\n",
            "Epoch: [13 / 15], batches: [100 / 782], loss: 0.477, acc: 83.59\n",
            "Epoch: [13 / 15], batches: [200 / 782], loss: 0.425, acc: 85.48\n",
            "Epoch: [13 / 15], batches: [300 / 782], loss: 0.466, acc: 83.95\n",
            "Epoch: [13 / 15], batches: [400 / 782], loss: 0.460, acc: 84.20\n",
            "Epoch: [13 / 15], batches: [500 / 782], loss: 0.464, acc: 83.66\n",
            "Epoch: [13 / 15], batches: [600 / 782], loss: 0.483, acc: 83.66\n",
            "Epoch: [13 / 15], batches: [700 / 782], loss: 0.479, acc: 83.61\n",
            "Epoch: [14 / 15], batches: [100 / 782], loss: 0.450, acc: 84.36\n",
            "Epoch: [14 / 15], batches: [200 / 782], loss: 0.425, acc: 85.80\n",
            "Epoch: [14 / 15], batches: [300 / 782], loss: 0.430, acc: 85.08\n",
            "Epoch: [14 / 15], batches: [400 / 782], loss: 0.451, acc: 84.61\n",
            "Epoch: [14 / 15], batches: [500 / 782], loss: 0.446, acc: 84.86\n",
            "Epoch: [14 / 15], batches: [600 / 782], loss: 0.441, acc: 84.91\n",
            "Epoch: [14 / 15], batches: [700 / 782], loss: 0.449, acc: 84.77\n",
            "Epoch: [15 / 15], batches: [100 / 782], loss: 0.439, acc: 84.91\n",
            "Epoch: [15 / 15], batches: [200 / 782], loss: 0.408, acc: 86.02\n",
            "Epoch: [15 / 15], batches: [300 / 782], loss: 0.431, acc: 85.05\n",
            "Epoch: [15 / 15], batches: [400 / 782], loss: 0.432, acc: 85.30\n",
            "Epoch: [15 / 15], batches: [500 / 782], loss: 0.453, acc: 84.11\n",
            "Epoch: [15 / 15], batches: [600 / 782], loss: 0.449, acc: 84.72\n",
            "Epoch: [15 / 15], batches: [700 / 782], loss: 0.417, acc: 85.89\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(vgg, PATH)"
      ],
      "metadata": {
        "id": "vMM8aNPMj0Tk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = VGG()\n",
        "\n",
        "load_model(net, PATH)"
      ],
      "metadata": {
        "id": "2rv6GgUhj0Iz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8d7329a-11e5-47f6-c345-49d3d98d63ec"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-5d561a9e3963>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(torch.load(PATH))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(net, testloader)"
      ],
      "metadata": {
        "id": "k0uxmwTejz6Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf04f8ba-c8a1-4d17-dd5a-379a33b2ea8c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 84 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_test(net, testloader)"
      ],
      "metadata": {
        "id": "TuwApWI-j8hM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a165fa2a-ebe1-4963-ac0a-f6aedfb11d83"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class plane is: 84.1 %\n",
            "Accuracy for class car   is: 94.0 %\n",
            "Accuracy for class bird  is: 81.0 %\n",
            "Accuracy for class cat   is: 71.6 %\n",
            "Accuracy for class deer  is: 86.5 %\n",
            "Accuracy for class dog   is: 70.9 %\n",
            "Accuracy for class frog  is: 93.0 %\n",
            "Accuracy for class horse is: 85.0 %\n",
            "Accuracy for class ship  is: 92.0 %\n",
            "Accuracy for class truck is: 87.3 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8bjmLK-_tYz"
      },
      "source": [
        "## Good Job!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}